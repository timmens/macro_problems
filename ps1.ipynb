{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "\n",
    "1. IV APPROACH\n",
    "2. PART 4 PLOTTING\n",
    "3. PART 4 EFFECT REMOVAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Macro 2: Problem Sheet 1\n",
    "\n",
    "### Exercise 1\n",
    "\n",
    "> **Remark 1.** This notebook is structured as follows. First I define all necessary functions in a sort of abstract fashion. Then at the very end I call all functions to produce numerical results and plots.\n",
    "\n",
    "> **Remark 2.** Either our data management contains errors or the data is not suitable for our analysis since many estimation steps need a subset of the data that is empty. See section [*Remark on the data*](#remark-on-the-data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statsmodels.formula.api import ols\n",
    "from joblib import Parallel\n",
    "from joblib import delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"data/CNEF_PSID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compose(f, g):\n",
    "    \"\"\"Composition of two functins.\n",
    "    \n",
    "    h(x) := f(g(x)) for all x\n",
    "    \n",
    "    \"\"\"\n",
    "    h = lambda x: f(g(x))\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yearly_variables(year):\n",
    "    \"\"\"Returns list and dict of relevant columns given year.\n",
    "    \n",
    "    Convert variables names to year specific names. For example instead\n",
    "    of 'x11102' writes 'x1110285' for the year '85. Additionally add\n",
    "    variable name for individual id.\n",
    "    \n",
    "    For details on variable names and more information seek the\n",
    "    codebook: https://www.cnefdata.org/documentation/codebooks\n",
    "    \n",
    "    \n",
    "    Args:\n",
    "        year (int): Year. (Write 85 for 1985.)\n",
    "        \n",
    "    Returns:\n",
    "        as_list (list): List of variable names.\n",
    "        as_dict (dict): Dict of variable name translation to human\n",
    "            readable form.\n",
    "    \n",
    "    \"\"\"\n",
    "    variables = {\n",
    "        \"x11102\": \"household\",\n",
    "        \"i11102\": \"income\",\n",
    "        \"d11105\": \"relationship_to_head\",\n",
    "        \"d11101\": \"age\",\n",
    "        \"d11109\": \"education\",\n",
    "        \"e11101\": \"hours\",\n",
    "    }\n",
    "    as_dict = {f\"{key}{year}\": value for key, value in variables.items()}\n",
    "    as_dict = dict(as_dict, **{\"x11101ll\": \"individual\"})\n",
    "    as_list = [f\"{key}{year}\" for key in variables.keys()]\n",
    "    as_list.append(\"x11101ll\")\n",
    "    return as_dict, as_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_given_year(year):\n",
    "    \"\"\"Load data and assign new columns given year.\n",
    "    \n",
    "    This already does some steps described in part 2 of exercise 1.\n",
    "    \n",
    "    Args:\n",
    "        year (int): Year. (Write 85 for 1985.)\n",
    "        \n",
    "    Returns:\n",
    "        df (pd.DataFrame): Data frame with columss\n",
    "    \n",
    "    \"\"\"\n",
    "    cols_mapper, cols = get_yearly_variables(year)\n",
    "\n",
    "    df = pd.read_stata(DATA_PATH / f\"pequiv{year}.dta\", columns=cols)\n",
    "\n",
    "    df = df.rename(columns=cols_mapper)\n",
    "    df = df.set_index([\"household\", \"individual\"])\n",
    "    df = df.dropna(how=\"all\")\n",
    "    df = df.assign(\n",
    "        **{\n",
    "            \"year\": year,\n",
    "            \"relationship_to_head\": df.relationship_to_head.str.split(\" \").apply(\n",
    "                lambda s: s[0]\n",
    "            ),\n",
    "        }\n",
    "    )\n",
    "    df = df.convert_dtypes()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    \"\"\"Clean data frame.\n",
    "    \n",
    "    This does most steps described in part 2 of exercise 1.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Frame produced by :func:`load_data_given_year`.\n",
    "        \n",
    "    Returns:\n",
    "        df (pd.DataFrame): Cleaned data frame.\n",
    "    \n",
    "    \"\"\"\n",
    "    TEN_PERCENT_OF_ANNUAL_FULLTIME_HOURS = 208\n",
    "\n",
    "    df = df.query(\"relationship_to_head in ['head', 'partner']\")\n",
    "    df = df.assign(\n",
    "        **{\n",
    "            \"is_single\": df.relationship_to_head.groupby(\"household\").transform(\n",
    "                lambda x: set(x) != {\"head\", \"partner\"}\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "    df = df.query(\"is_single == False\")\n",
    "\n",
    "    total = df.groupby(by=\"household\")[[\"hours\", \"income\"]].sum()\n",
    "\n",
    "    df = df.query(\"relationship_to_head == 'head'\")\n",
    "    df = df.reset_index(level=\"individual\")\n",
    "    df = df.assign(**{\"income\": total.income, \"hours\": total.hours})\n",
    "\n",
    "    df = df.query(\"25 <= age < 56\")\n",
    "    df = df.query(\"hours >= @TEN_PERCENT_OF_ANNUAL_FULLTIME_HOURS\")\n",
    "    df = df.query(\"income > 0\")\n",
    "\n",
    "    df = df.assign(**{\"income\": np.log(df.income)})\n",
    "\n",
    "    df = df.drop([\"relationship_to_head\", \"is_single\", \"hours\"], axis=1)\n",
    "    df = df.astype(\n",
    "        {\n",
    "            \"income\": float,\n",
    "            \"education\": \"category\",\n",
    "            \"age\": \"category\",\n",
    "            \"year\": \"category\",\n",
    "        }\n",
    "    )\n",
    "    df = df.set_index(\"age\", append=True)\n",
    "    df = df.dropna(how=\"any\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_data(n_jobs=1, load_from_disc=False):\n",
    "    \"\"\"Load, clean and merge data for years 1980 to 1997.\n",
    "    \n",
    "    Since loading and cleaning the data is time consuming there is\n",
    "    a check if the clean data is already available.\n",
    "    \n",
    "    Args:\n",
    "        n_jobs (int): Number of cores to use for parallelized data cleaning.\n",
    "        load_from_disc (bool): Should the dataset be loaded from disc if available.\n",
    "            Default False.\n",
    "    \n",
    "    Returns:\n",
    "        df (pd.DataFrame): Cleaned and merged data frame with index ['household', 'year']\n",
    "            and columns 'income', 'age', 'education' and 'work'. Column 'income' is float\n",
    "            while all other columns are category.\n",
    "    \n",
    "    \"\"\"\n",
    "    clean_data_path = DATA_PATH / \"clean_data.csv\"\n",
    "    if load_from_disc and clean_data_path.exists():\n",
    "        df = pd.read_csv(clean_data_path)\n",
    "    else:\n",
    "        _load_and_clean = compose(clean_data, load_data_given_year)\n",
    "        dfs = Parallel(n_jobs, prefer=\"processes\")(\n",
    "            delayed(_load_and_clean)(year) for year in range(80, 98)\n",
    "        )\n",
    "        df = pd.concat(dfs).sort_index().reset_index()\n",
    "        \n",
    "    df = df.drop_duplicates(subset=[\"household\", \"age\"], keep=\"first\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_dummy_regression(df):\n",
    "    \"\"\"Fit dummy regression on data in df.\n",
    "    \n",
    "    In the formula object C() tells statsmodels to use the variable as\n",
    "    categorical variable.\n",
    "    \n",
    "    \"\"\"\n",
    "    model = ols(\"income ~ C(year) + C(age) + C(education)\", data=df)\n",
    "    model = model.fit()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_quantities_approach_4(df):\n",
    "    \"\"\"Estimate quantities using approach in part 4.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Cleaned data with residuals.\n",
    "    \n",
    "    Returns:\n",
    "        quantities (pd.DataFrame): Estimates of rho, sigma_eps^2 and sigma_mu_tau^2.\n",
    "        var (pd.DataFrame): Sample variances.\n",
    "\n",
    "    \"\"\"\n",
    "    var = df.query(\"age in [25, 40, 55]\")[[\"age\", \"residuals\"]].groupby(\"age\").var()\n",
    "\n",
    "    _rho = (var.loc[55][0] - var.loc[40][0]) / (var.loc[40][0] - var.loc[25][0])\n",
    "    rho = _rho ** (1 / 30)\n",
    "    gamma = rho ** 2 * (1 - rho ** 30) / (1 - rho ** 2)\n",
    "\n",
    "    sigma_eps = (var.loc[40][0] - var.loc[25][0]) / gamma\n",
    "    sigma_mu_tau = var.loc[25][0] - sigma_eps\n",
    "\n",
    "    quantities = pd.DataFrame(\n",
    "        [rho, sigma_eps, sigma_mu_tau],\n",
    "        columns=[\"value\"],\n",
    "        index=[\"$\\rho$\", \"$\\sigma_{\\epsilon}^2$\", \"$\\sigma_{\\mu\\tau}^2$\"],\n",
    "    )\n",
    "    return quantities, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_quantities_approach_5(df, var):\n",
    "    \"\"\"Estimate quantities using approach in part 5.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Cleaned data with residuals.\n",
    "    \n",
    "    \"\"\"\n",
    "    forty_year_old_households = df.query(\"age == 40\")[\"household\"]\n",
    "    df = df.query(\"household in @forty_year_old_households\")\n",
    "\n",
    "    # compute (sample) covariances\n",
    "    combinations = [(40, 39), (40, 38), (40, 37)]\n",
    "    cov = pd.DataFrame(index=pd.MultiIndex.from_tuples(combinations))\n",
    "    for comb in combinations:\n",
    "\n",
    "        _df = df[[\"household\", \"age\", \"residuals\"]].query(\"age in @comb\")\n",
    "        idx = _df.groupby(\"household\")[\"age\"].transform(\n",
    "            lambda x: set(x) == set(comb) and len(x) == 2\n",
    "        )\n",
    "        _df = _df.loc[idx,].set_index([\"household\", \"age\"])\n",
    "\n",
    "        _cov = _df.unstack(level=\"age\").cov().values[0, 1]\n",
    "        cov.loc[comb, \"cov\"] = _cov\n",
    "\n",
    "    # compute quantities\n",
    "    rho = (\n",
    "        (cov.loc[(40, 37),] - cov.loc[(40, 38)])\n",
    "        / (cov.loc[(40, 38),] - cov.loc[(40, 39)])\n",
    "    )[0]\n",
    "\n",
    "    sigma_eps = (\n",
    "        (cov.loc[(40, 37),] - cov.loc[(40, 37),])[0]\n",
    "        * (1 - rho ** 2)\n",
    "        / (rho * (rho - 1) * (rho ** 29 + 1))\n",
    "    )\n",
    "    sigma_mu = cov.loc[(40, 39),][0] - sigma_eps * rho * (1 - rho ** 30) / (\n",
    "        1 - rho ** 2\n",
    "    )\n",
    "    sigma_tau = var.loc[25][0] - sigma_mu - sigma_eps\n",
    "\n",
    "    quantities = pd.DataFrame(\n",
    "        [rho, sigma_eps, sigma_mu, sigma_tau],\n",
    "        columns=[\"value\"],\n",
    "        index=[\n",
    "            \"$\\rho$\",\n",
    "            \"$\\sigma_{\\epsilon}^2$\",\n",
    "            \"$\\sigma_{\\mu}^2$\",\n",
    "            \"$\\sigma_{\\tau}^2$\",\n",
    "        ],\n",
    "    )\n",
    "    return quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_rho_approach_iv(df, n_jobs=1):\n",
    "    \"\"\"Estimate rho using an instrumental variable approach.\n",
    "    \n",
    "    Regression equation:\n",
    "        \n",
    "        (1)   x_{ih}* = rho x_{i, h-1}* + error\n",
    "        \n",
    "    Equation (1) has an endogeneity problem, hence we will construct\n",
    "    a valid instrument z_{i, h-1} for x_{i, h-1}* and estimate rho\n",
    "    using 2SLS.\n",
    "    \n",
    "    (!) A minimum requirement for this to work is that for *some* number\n",
    "    of observations x_{ih}* AND x_{i, h-1}* is observed.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Cleaned data with residuals.\n",
    "        n_jobs (int): Number of cores to use for parallelized data cleaning.\n",
    "        \n",
    "    Returns:\n",
    "    \n",
    "        ... MISSING ...\n",
    "    \n",
    "    \"\"\"\n",
    "    def _create_instrument_or_return_nan(household, age, df):\n",
    "        try:\n",
    "            instrument = df.loc[(household, age - 1), \"residual\"] - df.loc[(household, age - 2), \"residual\"]\n",
    "        except KeyError:\n",
    "            instrument = np.nan\n",
    "            \n",
    "        try:\n",
    "            lagged_residual = df.loc[(household, age - 1), \"residual\"]\n",
    "        except KeyError:\n",
    "            lagged_residual = np.nan\n",
    "            \n",
    "        return instrument, lagged_residual\n",
    "    \n",
    "    df = df.set_index([\"household\", \"age\"])\n",
    "    \n",
    "    to_parallelize = partial(_create_instrument_or_return_nan, **{\"df\": df})\n",
    "    results = Parallel(n_jobs, prefer=\"processes\")(\n",
    "        delayed(to_parallelize)(household, age) for household, age in df.index\n",
    "    )\n",
    "    results = pd.DataFrame(results, columns=[\"instrument\", \"lagged_residuals\"], index=df.index)\n",
    "    \n",
    "    df = pd.concat((df, results), axis=1)\n",
    "\n",
    "    # from statsmodels.formula.api import mixedlm\n",
    "    # https://www.statsmodels.org/stable/mixed_linear.html\n",
    "    # model = mixedlm(\"residual ~ lagged_residual\", data=df, groups=df.index.get_level_values(\"household\"))\n",
    "    # check out: https://bashtage.github.io/linearmodels/doc/index.html\n",
    "    \n",
    "    quantity = pd.Series([np.nan], index=[\"$\\rho$\"], name=\"value\").to_frame()\n",
    "    return quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_parts(part4, part5, part6):\n",
    "    \"\"\"Combine results from part4 to part6 in one data frame.\"\"\"\n",
    "    keys = [\"part4\", \"part5\", \"part6\"]\n",
    "    df = pd.concat((part4, part5, part6), axis=1, keys=keys)\n",
    "    df = df.droplevel(level=1, axis=1)\n",
    "    df = df.convert_dtypes()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remark on the Data\n",
    "\n",
    "Before we continue with the actual computation let me make some remarks about the data and why we will expect non-robust estimates from it. All complaints about the data rely on the fact that the data cleaning step are correct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_and_clean_data(n_jobs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Remark 3.** Apparently the individual who is reported to be household head can change over the years. This causes complications like the following, where for a single household head the age and year columns don't quite match. Furthermore as this example already shows, the age column of an observation is very messy and we do not have many consecutive observations. This will later cause problems for the covariance estimation (part 5) and for the instrument creation (part 6) ---see remark 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>household</th>\n",
       "      <th>age</th>\n",
       "      <th>individual</th>\n",
       "      <th>income</th>\n",
       "      <th>education</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1397004.0</td>\n",
       "      <td>11.306651</td>\n",
       "      <td>17</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>5065172.0</td>\n",
       "      <td>10.562056</td>\n",
       "      <td>11</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>733001.0</td>\n",
       "      <td>10.888048</td>\n",
       "      <td>13</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   household  age  individual     income  education  year\n",
       "0          1   35   1397004.0  11.306651         17    91\n",
       "1          1   41   5065172.0  10.562056         11    83\n",
       "3          1   54    733001.0  10.888048         13    82"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query(\"household == 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Model and use Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fit_dummy_regression(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(**{\"residuals\": model.resid})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results for Part 4, 5 and 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "part4, var = estimate_quantities_approach_4(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "part5 = estimate_quantities_approach_5(df, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "part6 = estimate_rho_approach_iv(df, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = combine_parts(part4, part5, part6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part4</th>\n",
       "      <th>part5</th>\n",
       "      <th>part6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>$\\rho$</th>\n",
       "      <td>1.010213</td>\n",
       "      <td>1.212954</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\sigma_{\\epsilon}^2$</th>\n",
       "      <td>0.002043</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\sigma_{\\mu\\tau}^2$</th>\n",
       "      <td>0.19632</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\sigma_{\\mu}^2$</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.01092</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\sigma_{\\tau}^2$</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.187443</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          part4     part5  part6\n",
       "$\\rho$                 1.010213  1.212954   <NA>\n",
       "$\\sigma_{\\epsilon}^2$  0.002043      -0.0   <NA>\n",
       "$\\sigma_{\\mu\\tau}^2$    0.19632      <NA>   <NA>\n",
       "$\\sigma_{\\mu}^2$           <NA>   0.01092   <NA>\n",
       "$\\sigma_{\\tau}^2$          <NA>  0.187443   <NA>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
